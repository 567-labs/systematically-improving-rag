{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook shows how to make synthetic data to bootstrap evaluation of your retrieval system. \n",
    "\n",
    "This synthetic data contains many triplets of `(RAG system input, system output, desired chunk to retrieve)`. For this example, we will work on a hardware retailer's system to answer user questions based on existing product previous. So the synthetic data will look like\n",
    "\n",
    "```\n",
    "Q: How frequently do I need to replace the blades on this saw?\n",
    "A: A customer reported getting 7-10 hours of active use between blade replacements.\n",
    "Chunk ID: 3\n",
    "```\n",
    "\n",
    "Once you have many of these triplets, you can experiments with different retrieval strategies (e.g. different embedding models, embedding vs keyword search, etc) to determine which strategies most consistently retrieve the desired chunks.\n",
    "\n",
    "# A Starting Point\n",
    "\n",
    "A simple approach would follow pseudo code:\n",
    "\n",
    "```\n",
    "synth_data = []\n",
    "for chunk in corpus:\n",
    "    response = call_llm(f\"Give me a JSON array of 10 question/answer pairs. The questions should be things someone might ask about a product before purchase. The answer should be something contained in this text: {chunk}\")\n",
    "    q_a = json.loads(response.content)\n",
    "    q_a_c = [{'question': q, 'answer': a, 'chunk': chunk} for (q, a) in q_a_pairs]\n",
    "    synth_data.extend(q_a_c)\n",
    "```\n",
    "\n",
    "A practical implementation should address three issues that arise in the naive pseudo code.\n",
    "\n",
    "| Issue | Solution |\n",
    "|---------|----------|\n",
    "| Inconsistent formatting of LLM response (e.g. different keys) | Instructor library |\n",
    "| Bad questions | Guidance/examples in prompt |\n",
    "| Time waiting for LLM responses when iterating over many chunks | Async LLM calls|\n",
    "\n",
    "# Reusable Code to Bootstrap Evals\n",
    "\n",
    "The code in this notebook addresses these issues. The code is also available as [this script](https://gist.github.com/jxnl/5627c9d463ffe0b085896f7890fab1bf).\n",
    "\n",
    "## Data\n",
    "\n",
    "This course uses synthetic data based on the use-case of answering questions on a hardware retailer's website based on product reviews. We have created this data in `make_product_reviews.ipynb`. Here is a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I've been using this cordless drill for about six months now, and it has exceeded my expectations. The lithium-ion battery lasts a long time, allowing me to...\n",
       "1       This cordless drill is a game-changer for my DIY projects. The powerful battery charges quickly and holds its charge well, even when not in use. I appreciat...\n",
       "2       I purchased this cordless drill for some home renovation work, and it has been fantastic. The battery life is impressive, and the drill itself is very power...\n",
       "3       As a professional contractor, I need reliable tools, and this cordless drill fits the bill perfectly. The lithium-ion battery provides consistent power, and...\n",
       "4       This is by far the best cordless drill I've ever owned. The battery life is outstanding, and it recharges quickly. The multiple speed settings are perfect f...\n",
       "                                                                                     ...                                                                               \n",
       "1801    I purchased this garden tiller to help with my raised garden beds, and it has exceeded my expectations. The lightweight design makes it easy to lift and mov...\n",
       "1802    As a novice gardener, I was looking for a tool that would make soil preparation less daunting, and this garden tiller has been perfect. The easy access desi...\n",
       "1803    This garden tiller has been a fantastic addition to my gardening toolkit. The compact design is ideal for my small garden, and the tiller is powerful enough...\n",
       "1804    I've tried several garden tillers over the years, and this one is by far the best. The lightweight design makes it easy to maneuver, and the tiller blades a...\n",
       "1805    I bought this garden tiller to help with my community garden plot, and it has been a great investment. The compact size allows me to transport it easily in ...\n",
       "Name: review, Length: 1806, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "reviews_table = db.open_table(\"reviews\")\n",
    "sample_reviews = reviews_table.to_pandas()\n",
    "sample_reviews.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure The Data\n",
    "\n",
    "We use Pydantic & Instructor for a reliable interface between our LLMs and the structured data formats we need to run code on LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    id: str\n",
    "    product_title: str\n",
    "    product_description: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "sample_chunks = [\n",
    "    Review(\n",
    "        id=str(row.id),\n",
    "        product_title=row.product_title,\n",
    "        product_description=row.product_description,\n",
    "        review=row.review,\n",
    "    )\n",
    "    for _, row in sample_reviews.iterrows()\n",
    "]\n",
    "\n",
    "n_questions = 2  # number of questions to get in each LLM call\n",
    "example_questions = [\n",
    "    \"What does the reviewer like about the product?\",\n",
    "    \"What does the reviewer think could be improved?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see how we build questions on a single chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How long does the battery last on this cordless drill?', answer='The lithium-ion battery lasts a long time, allowing for multiple projects on a single charge.', chunk_id='0'),\n",
       " ChunkEval(question='Is this cordless drill comfortable to use for long periods?', answer='Yes, the comfortable grip means it can be used for extended periods without fatigue.', chunk_id='0')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Patch the AsyncOpenAI client\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class ChunkEval(QuestionAnswer):\n",
    "    chunk_id: str\n",
    "\n",
    "\n",
    "async def generate_evals(\n",
    "    review: Review, n_questions: int, example_questions: List[str]\n",
    ") -> List[ChunkEval]:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate `{n_questions}` question-answer pairs about a {review.product_title}. The answers should primarily be derived from information in this product review:\n",
    "\n",
    "        <content>\n",
    "        {review.review}\n",
    "        </content>\n",
    "\n",
    "        While they should contain information from the product review, you may also find it helpful context to see a product description:\n",
    "        <content>\n",
    "        {review.product_description}\n",
    "        </content>\n",
    "\n",
    "        Example questions:\n",
    "        {chr(10).join(f'- {q}' for q in example_questions)}\n",
    "\n",
    "        Provide a concise and specific answer for each question.\n",
    "        Do not use the exact example questions. Use them only as inspiration for the types of more specific questions to generate.\n",
    "        Do not include answers that are not in the content.\n",
    "        Questions should ask about product characteristics (e.g. durability) and answers should refer to product characteristics without referring to the reviewer specifically.\n",
    "        Stylistically, the questions should resemble what people would ask a RAG-based answer bot on a retailer's website. So they can be a little informal, messy or scattered.\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        pairs = client.chat.completions.create_iterable(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=QuestionAnswer,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        return [\n",
    "            ChunkEval(question=pair.question, answer=pair.answer, chunk_id=review.id)\n",
    "            async for pair in pairs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "first_chunk_res = await generate_evals(sample_chunks[0], n_questions, example_questions)\n",
    "first_chunk_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `generate_evals` for many chunks in parallel, wrap it with a function that also takes a semaphore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How long does the battery last on this cordless drill?', answer='The lithium-ion battery lasts a long time, allowing for multiple projects on a single charge.', chunk_id='0'),\n",
       " ChunkEval(question='Is this cordless drill comfortable to use for long periods?', answer='Yes, the comfortable grip means it can be used for extended periods without fatigue.', chunk_id='0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "class ChunkProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "async def process_chunk(\n",
    "    review: Review,\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    semaphore: asyncio.Semaphore,\n",
    ") -> List[ChunkEval]:\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            return await generate_evals(review, n_questions, example_questions)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing chunk {review.id}: {str(e)}\")\n",
    "            raise ChunkProcessingError(f\"Failed to process chunk {review.id}\") from e\n",
    "\n",
    "\n",
    "# Test that we get the same results as directly calling generate_evals\n",
    "await process_chunk(\n",
    "    sample_chunks[0], n_questions, example_questions, asyncio.Semaphore(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call `process_chunks` with all chunks to build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3612 ChunkEvals.\n",
      "Dataset saved as 'synthetic_eval_dataset.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    reviews: List[Review],\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    max_concurrency: int = 10,\n",
    ") -> List[ChunkEval]:\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [\n",
    "        process_chunk(review, n_questions, example_questions, semaphore)\n",
    "        for review in reviews\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = []\n",
    "    for result in results:\n",
    "        if isinstance(result, ChunkProcessingError):\n",
    "            print(result)\n",
    "        elif isinstance(result, list):\n",
    "            dataset.extend(result)\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(result)}\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_dataset(dataset: List[ChunkEval], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump([chunk_eval.model_dump() for chunk_eval in dataset], f, indent=2)\n",
    "\n",
    "\n",
    "synthetic_dataset = await create_synthetic_dataset(\n",
    "    sample_chunks, n_questions, example_questions\n",
    ")\n",
    "save_dataset(synthetic_dataset, \"synthetic_eval_dataset.json\")\n",
    "\n",
    "print(f\"Generated {len(synthetic_dataset)} ChunkEvals.\")\n",
    "print(\"Dataset saved as 'synthetic_eval_dataset.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How long does the battery last on this cordless drill?</td>\n",
       "      <td>The lithium-ion battery lasts a long time, allowing for multiple projects on a single charge.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is this cordless drill comfortable to use for long periods?</td>\n",
       "      <td>Yes, the comfortable grip means it can be used for extended periods without fatigue.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long does the battery last on this cordless drill?</td>\n",
       "      <td>The powerful battery charges quickly and holds its charge well, even when not in use.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this drill comfortable to use for extended periods?</td>\n",
       "      <td>The ergonomic design and lightweight build make it comfortable to use for hours on end.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How's the battery life on this cordless drill?</td>\n",
       "      <td>The battery life is impressive.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      question  \\\n",
       "0       How long does the battery last on this cordless drill?   \n",
       "1  Is this cordless drill comfortable to use for long periods?   \n",
       "2       How long does the battery last on this cordless drill?   \n",
       "3       Is this drill comfortable to use for extended periods?   \n",
       "4               How's the battery life on this cordless drill?   \n",
       "\n",
       "                                                                                          answer  \\\n",
       "0  The lithium-ion battery lasts a long time, allowing for multiple projects on a single charge.   \n",
       "1           Yes, the comfortable grip means it can be used for extended periods without fatigue.   \n",
       "2          The powerful battery charges quickly and holds its charge well, even when not in use.   \n",
       "3        The ergonomic design and lightweight build make it comfortable to use for hours on end.   \n",
       "4                                                                The battery life is impressive.   \n",
       "\n",
       "  chunk_id  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(i.question, i.answer, i.chunk_id) for i in synthetic_dataset]\n",
    "pd.DataFrame(data, columns=[\"question\", \"answer\", \"chunk_id\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
