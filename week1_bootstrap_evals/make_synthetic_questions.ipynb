{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook shows how to make synthetic data to bootstrap evaluation of your retrieval system. \n",
    "\n",
    "This synthetic data contains many triplets of `(RAG system input, system output, desired chunk to retrieve)`. For this example, we will work on a hardware retailer's system to answer user questions based on existing product previous. So the synthetic data will look like\n",
    "\n",
    "```\n",
    "Q: How frequently do I need to replace the blades on this saw?\n",
    "A: A customer reported getting 7-10 hours of active use between blade replacements.\n",
    "Chunk ID: 3\n",
    "```\n",
    "\n",
    "Once you have many of these triplets, you can experiments with different retrieval strategies (e.g. different embedding models, embedding vs keyword search, etc) to determine which strategies most consistently retrieve the desired chunks.\n",
    "\n",
    "# A Starting Point\n",
    "\n",
    "A simple approach would follow pseudo code:\n",
    "\n",
    "```\n",
    "synth_data = []\n",
    "for chunk in corpus:\n",
    "    response = call_llm(f\"Give me a JSON array of 10 question/answer pairs. The questions should be things someone might ask about a product before purchase. The answer should be something contained in this text: {chunk}\")\n",
    "    q_a = json.loads(response.content)\n",
    "    q_a_c = [{'question': q, 'answer': a, 'chunk': chunk} for (q, a) in q_a_pairs]\n",
    "    synth_data.extend(q_a_c)\n",
    "```\n",
    "\n",
    "A practical implementation should address three issues that arise in the naive pseudo code.\n",
    "\n",
    "| Issue | Solution |\n",
    "|---------|----------|\n",
    "| Inconsistent formatting of LLM response (e.g. different keys) | Instructor library |\n",
    "| Bad questions | Guidance/examples in prompt |\n",
    "| Time waiting for LLM responses when iterating over many chunks | Async LLM calls|\n",
    "\n",
    "# Reusable Code to Bootstrap Evals\n",
    "\n",
    "The code in this notebook addresses these issues. The code is also available as [this script](https://gist.github.com/jxnl/5627c9d463ffe0b085896f7890fab1bf).\n",
    "\n",
    "## Data\n",
    "\n",
    "This course uses synthetic data based on the use-case of answering questions on a hardware retailer's website based on product reviews. We have created this data in `make_product_reviews.ipynb`. Here is a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I've owned several cordless drills over the years, but this one is exceptional. It is lightweight, making it easy to use for extended periods without fatigu...\n",
       "1       As a professional contractor, I rely on my tools every day. This cordless drill has exceeded my expectations with its powerful motor and ergonomic design. T...\n",
       "2       I'm a DIY enthusiast and bought this cordless drill for home projects. It's perfect for everything from hanging shelves to assembling furniture. The drill i...\n",
       "3       After using this cordless drill for several months, I can confidently say it's one of the best I've owned. The lightweight design makes it comfortable to us...\n",
       "4       This cordless drill has become my go-to tool for all my DIY projects. The lightweight design reduces strain on my wrist, and the 2-speed transmission is inc...\n",
       "                                                                                     ...                                                                               \n",
       "1130    What I love most about this pressure cookware is how quickly it builds and releases pressure. The pot itself is lightweight yet durable, making it easy to h...\n",
       "1131    This pressure cooker has exceeded my expectations with its performance and design. It's perfect for preparing large batches of soups and stews. The pressure...\n",
       "1132    I bought this pressure cooker primarily for its versatility, and it has lived up to my hopes. It works effortlessly on my ceramic stovetop, and the fast coo...\n",
       "1133    The build quality of this pressure cookware is top-notch. The handles are ergonomically designed, making it easy to lift and move around. I love that it com...\n",
       "1134    After using this pressure cooker for a few months, I can say it's one of the best kitchen investments I've made. The even heat distribution ensures that my ...\n",
       "Name: review, Length: 1135, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "reviews_table = db.open_table(\"reviews\")\n",
    "sample_reviews = reviews_table.to_pandas()\n",
    "sample_reviews.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure The Data\n",
    "\n",
    "We use Pydantic & Instructor for a reliable interface between our LLMs and the structured data formats we need to run code on LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    id: str\n",
    "    product_title: str\n",
    "    product_description: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "sample_chunks = [\n",
    "    Review(\n",
    "        id=str(row.id),\n",
    "        product_title=row.product_title,\n",
    "        product_description=row.product_description,\n",
    "        review=row.review,\n",
    "    )\n",
    "    for _, row in sample_reviews.iterrows()\n",
    "]\n",
    "\n",
    "n_questions = 2  # number of questions to get in each LLM call\n",
    "example_questions = [\n",
    "    \"What does the reviewer like about the product?\",\n",
    "    \"What does the reviewer think could be improved?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see how we build questions on a single chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How does the weight of this cordless drill affect its usability?', answer='The cordless drill is lightweight, making it easy to use for extended periods without fatigue.', chunk_id='0'),\n",
       " ChunkEval(question='What features does this drill have for different tasks?', answer='It has a 2-speed transmission that allows switching between high torque for drilling and high speed for driving screws.', chunk_id='0')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Patch the AsyncOpenAI client\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class ChunkEval(QuestionAnswer):\n",
    "    chunk_id: str\n",
    "\n",
    "\n",
    "async def generate_evals(\n",
    "    review: Review, n_questions: int, example_questions: List[str]\n",
    ") -> List[ChunkEval]:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate `{n_questions}` question-answer pairs about a {review.product_title}. The answers should primarily be derived from information in this product review:\n",
    "\n",
    "        <content>\n",
    "        {review.review}\n",
    "        </content>\n",
    "\n",
    "        While they should contain information from the product review, you may also find it helpful context to see a product description:\n",
    "        <content>\n",
    "        {review.product_description}\n",
    "        </content>\n",
    "\n",
    "        Example questions:\n",
    "        {chr(10).join(f'- {q}' for q in example_questions)}\n",
    "\n",
    "        Provide a concise and specific answer for each question.\n",
    "        Do not use the exact example questions. Use them only as inspiration for the types of more specific questions to generate.\n",
    "        Do not include answers that are not in the content.\n",
    "        Questions should ask about product characteristics (e.g. durability) and answers should refer to product characteristics without referring to the reviewer specifically.\n",
    "        Stylistically, the questions should resemble what people would ask a RAG-based answer bot on a retailer's website. So they can be a little informal, messy or scattered.\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        pairs = client.chat.completions.create_iterable(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=QuestionAnswer,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return [\n",
    "            ChunkEval(question=pair.question, answer=pair.answer, chunk_id=review.id)\n",
    "            async for pair in pairs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "first_chunk_res = await generate_evals(sample_chunks[0], n_questions, example_questions)\n",
    "first_chunk_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `generate_evals` for many chunks in parallel, wrap it with a function that also takes a semaphore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How heavy is this cordless drill compared to others on the market?', answer='This cordless drill is lightweight, making it easy to use for extended periods without fatigue.', chunk_id='0'),\n",
       " ChunkEval(question='What kind of tasks can this drill handle?', answer='The drill handles heavy-duty tasks with ease, thanks to its top-notch build quality and 2-speed transmission that allows for high torque and high speed.', chunk_id='0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "class ChunkProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "async def process_chunk(\n",
    "    review: Review,\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    semaphore: asyncio.Semaphore,\n",
    ") -> List[ChunkEval]:\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            return await generate_evals(review, n_questions, example_questions)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing chunk {review.id}: {str(e)}\")\n",
    "            raise ChunkProcessingError(f\"Failed to process chunk {review.id}\") from e\n",
    "\n",
    "\n",
    "# Test that we get the same results as directly calling generate_evals\n",
    "await process_chunk(\n",
    "    sample_chunks[0], n_questions, example_questions, asyncio.Semaphore(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call `process_chunks` with all chunks to build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2270 ChunkEvals.\n",
      "Dataset saved as 'synthetic_eval_dataset.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    reviews: List[Review],\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    max_concurrency: int = 10,\n",
    ") -> List[ChunkEval]:\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [\n",
    "        process_chunk(review, n_questions, example_questions, semaphore)\n",
    "        for review in reviews\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = []\n",
    "    for result in results:\n",
    "        if isinstance(result, ChunkProcessingError):\n",
    "            print(result)\n",
    "        elif isinstance(result, list):\n",
    "            dataset.extend(result)\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(result)}\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_dataset(dataset: List[ChunkEval], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump([chunk_eval.model_dump() for chunk_eval in dataset], f, indent=2)\n",
    "\n",
    "\n",
    "synthetic_dataset = await create_synthetic_dataset(\n",
    "    sample_chunks, n_questions, example_questions\n",
    ")\n",
    "save_dataset(synthetic_dataset, \"synthetic_eval_dataset.json\")\n",
    "\n",
    "print(f\"Generated {len(synthetic_dataset)} ChunkEvals.\")\n",
    "print(\"Dataset saved as 'synthetic_eval_dataset.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How good is the battery life on this cordless drill?</td>\n",
       "      <td>It comes with two included batteries, ensuring that you never run out of power on the job.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is this cordless drill easy to handle for long tasks?</td>\n",
       "      <td>Yes, its lightweight design makes it easy to use for extended periods without fatigue.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How powerful is the motor in this cordless drill?</td>\n",
       "      <td>The cordless drill features a powerful motor that exceeds expectations for professional use.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What design features make this drill suitable for overhead tasks?</td>\n",
       "      <td>The cordless drill has a lightweight design and ergonomic build, making it perfect for overhead tasks.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How durable are the batteries for this cordless drill?</td>\n",
       "      <td>The batteries charge quickly and last a long time, which is a huge plus.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            question  \\\n",
       "0               How good is the battery life on this cordless drill?   \n",
       "1              Is this cordless drill easy to handle for long tasks?   \n",
       "2                  How powerful is the motor in this cordless drill?   \n",
       "3  What design features make this drill suitable for overhead tasks?   \n",
       "4             How durable are the batteries for this cordless drill?   \n",
       "\n",
       "                                                                                                   answer  \\\n",
       "0              It comes with two included batteries, ensuring that you never run out of power on the job.   \n",
       "1                  Yes, its lightweight design makes it easy to use for extended periods without fatigue.   \n",
       "2            The cordless drill features a powerful motor that exceeds expectations for professional use.   \n",
       "3  The cordless drill has a lightweight design and ergonomic build, making it perfect for overhead tasks.   \n",
       "4                                The batteries charge quickly and last a long time, which is a huge plus.   \n",
       "\n",
       "  chunk_id  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(i.question, i.answer, i.chunk_id) for i in synthetic_dataset]\n",
    "pd.DataFrame(data, columns=[\"question\", \"answer\", \"chunk_id\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
