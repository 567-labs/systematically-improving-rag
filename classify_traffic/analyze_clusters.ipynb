{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "Projects have a fixed amount of time/effort available to improve the retrieval pipeline, so you need to prioritize where you spend your effort. You'll want to spend effort on improvements that\n",
    "1. Affect many queries\n",
    "2. Affect queries with room for improvement\n",
    "3. Affect high value queries\n",
    "\n",
    "This notebook shows how to monitor production traffic and identify what areas to improve (focusing on criteria 1 and 2 above).\n",
    "\n",
    "Specifically, we use an LLM to categorize queries into different topics or functionality areas. We can do basic analytics to detect\n",
    "1. Which categories have many queries\n",
    "2. Which categories have measures of low customer satisfaction\n",
    "\n",
    "We could do further analytics to look at how these stats change over time (e.g. as we bring in new types of users).\n",
    "\n",
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'How does the weight of this claw hammer compare to the ProHammer 2000?',\n",
       "  'product': {'title': 'Hammer',\n",
       "   'description': 'A versatile claw hammer for general carpentry and home repair. Features an ergonomic grip and balanced weight for efficient and comfortable use.'},\n",
       "  'thumbs_up': False},\n",
       " {'question': 'Is the ergonomic grip of this hammer more comfortable than the GripMaster 300?',\n",
       "  'product': {'title': 'Hammer',\n",
       "   'description': 'A versatile claw hammer for general carpentry and home repair. Features an ergonomic grip and balanced weight for efficient and comfortable use.'},\n",
       "  'thumbs_up': False},\n",
       " {'question': 'In terms of versatility, how does this hammer stack up against the MultiTool Hammer Pro?',\n",
       "  'product': {'title': 'Hammer',\n",
       "   'description': 'A versatile claw hammer for general carpentry and home repair. Features an ergonomic grip and balanced weight for efficient and comfortable use.'},\n",
       "  'thumbs_up': False}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "import instructor\n",
    "import json\n",
    "from openai import AsyncOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "from question_types import (\n",
    "    UntypedQuestion,\n",
    "    TypedQuestion,\n",
    "    Question,\n",
    "    Product,\n",
    "    QuestionTypes,\n",
    "    question_type_details,\n",
    ")\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "def read_to_question(q: dict) -> UntypedQuestion:\n",
    "    question = Question(text=q[\"question\"])\n",
    "    product = Product(title=q[\"product\"][\"title\"], description=q[\"product\"][\"description\"])\n",
    "    return UntypedQuestion(question=question, product=product, thumbs_up=q[\"thumbs_up\"])\n",
    "\n",
    "with open(\"prod_questions.json\", \"r\") as f:\n",
    "    prod_questions = json.load(f)\n",
    "    untyped_questions = [read_to_question(q) for q in prod_questions]\n",
    "\n",
    "prod_questions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Queries\n",
    "\n",
    "The raw query types are defined in `question_types.py`. We include these in our prompt and ask an LLM to categorize each question. We could either categorize each question into a single category or into multiple categories. This example categorizes into a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "q_type_explanation_list = [\n",
    "    f\"NAME: {q.title}\\nDESCRIPTION: {q.description}\\nEXAMPLE: {q.example}\"\n",
    "    for q in question_type_details.values()\n",
    "]\n",
    "\n",
    "q_type_explanation_str = \"\\n---\\n\".join(q_type_explanation_list)\n",
    "\n",
    "\n",
    "async def categorize_question(\n",
    "    question: UntypedQuestion, semaphore: asyncio.Semaphore = asyncio.Semaphore(1)\n",
    ") -> TypedQuestion:\n",
    "    async with semaphore:\n",
    "        question_text = question.question.text\n",
    "        prompt = f\"\"\"\n",
    "        Classify the attached question into one of the following categories:\n",
    "        {', '.join([q.value for q in QuestionTypes])}\n",
    "\n",
    "        Here are descriptions of each category:\n",
    "        {q_type_explanation_str}\n",
    "\n",
    "        Here is the question:\n",
    "        Question: {question_text}\n",
    "\n",
    "        For your context, here the product is on a hardware store website with the following description:\n",
    "        {question.product.description}\n",
    "\n",
    "        Respond with only the category name.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            result = await async_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                response_model=str,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            )\n",
    "\n",
    "            # Convert the string result to the corresponding QuestionTypes enum\n",
    "            question_type = QuestionTypes(result)\n",
    "\n",
    "            return TypedQuestion(\n",
    "                question=question.question,\n",
    "                question_type=question_type,\n",
    "                product=question.product,\n",
    "                thumbs_up=question.thumbs_up,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying question: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for all questions (using async patterns since we have many questions, and our time will be spent primarily waiting for API responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def categorize_questions(max_concurrency: int = 20) -> List[TypedQuestion]:\n",
    "    out = []\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [categorize_question(o, semaphore) for o in untyped_questions]\n",
    "    categorized_questions = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    for cq in categorized_questions:\n",
    "        if not isinstance(cq, Exception):\n",
    "            out.append(cq)\n",
    "        else:\n",
    "            print(f\"Error categorizing question: {str(cq)}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "categorized_questions = await categorize_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "Convert the data into a DataFrame and calculate basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_type</th>\n",
       "      <th>product_title</th>\n",
       "      <th>thumbs_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the weight of this claw hammer compar...</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the ergonomic grip of this hammer more comf...</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In terms of versatility, how does this hammer ...</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does this hammer provide better balance compar...</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the durability of this claw hammer co...</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text question_type  \\\n",
       "0  How does the weight of this claw hammer compar...    Comparison   \n",
       "1  Is the ergonomic grip of this hammer more comf...    Comparison   \n",
       "2  In terms of versatility, how does this hammer ...    Comparison   \n",
       "3  Does this hammer provide better balance compar...    Comparison   \n",
       "4  How does the durability of this claw hammer co...    Comparison   \n",
       "\n",
       "  product_title  thumbs_up  \n",
       "0        Hammer      False  \n",
       "1        Hammer      False  \n",
       "2        Hammer      False  \n",
       "3        Hammer      False  \n",
       "4        Hammer      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_questions = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"question_text\": q.question.text,\n",
    "            \"question_type\": q.question_type.value,\n",
    "            \"product_title\": q.product.title,\n",
    "            \"thumbs_up\": q.thumbs_up,\n",
    "        }\n",
    "        for q in categorized_questions\n",
    "        if q is not None\n",
    "    ]\n",
    ")\n",
    "clustered_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>fraction_thumbs_up</th>\n",
       "      <th>count_not_thumbs_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comparison</td>\n",
       "      <td>404</td>\n",
       "      <td>0.16</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Materials</td>\n",
       "      <td>275</td>\n",
       "      <td>0.23</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Time Sensitive</td>\n",
       "      <td>263</td>\n",
       "      <td>0.06</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compatibility</td>\n",
       "      <td>255</td>\n",
       "      <td>0.75</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country of Origin</td>\n",
       "      <td>248</td>\n",
       "      <td>0.61</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Authenticity and counterfeits</td>\n",
       "      <td>244</td>\n",
       "      <td>0.08</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Environmental Impact</td>\n",
       "      <td>218</td>\n",
       "      <td>0.13</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>General</td>\n",
       "      <td>201</td>\n",
       "      <td>0.69</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>154</td>\n",
       "      <td>0.63</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>94</td>\n",
       "      <td>0.29</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Visual</td>\n",
       "      <td>93</td>\n",
       "      <td>0.13</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TypicalPrice</td>\n",
       "      <td>82</td>\n",
       "      <td>0.27</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_type  num_questions  fraction_thumbs_up  \\\n",
       "2                      Comparison            404                0.16   \n",
       "8                       Materials            275                0.23   \n",
       "9                  Time Sensitive            263                0.06   \n",
       "3                   Compatibility            255                0.75   \n",
       "4               Country of Origin            248                0.61   \n",
       "1   Authenticity and counterfeits            244                0.08   \n",
       "6            Environmental Impact            218                0.13   \n",
       "7                         General            201                0.69   \n",
       "5                Customer Service            154                0.63   \n",
       "0                     Accessories             94                0.29   \n",
       "11                         Visual             93                0.13   \n",
       "10                   TypicalPrice             82                0.27   \n",
       "\n",
       "    count_not_thumbs_up  \n",
       "2                   341  \n",
       "8                   212  \n",
       "9                   247  \n",
       "3                    64  \n",
       "4                    96  \n",
       "1                   224  \n",
       "6                   189  \n",
       "7                    62  \n",
       "5                    57  \n",
       "0                    67  \n",
       "11                   81  \n",
       "10                   60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_stats = (\n",
    "    clustered_questions.groupby(\"question_type\")\n",
    "    .agg(\n",
    "        num_questions=(\"question_text\", \"size\"),\n",
    "        fraction_thumbs_up=(\"thumbs_up\", \"mean\"),\n",
    "        count_not_thumbs_up=(\"thumbs_up\", lambda x: x.size - x.sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cluster_stats.round(2).sort_values(\"num_questions\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "What areas would you prioritize?\n",
    "\n",
    "Some candidates would be\n",
    "- Bring in reviews from multiple products since it's so common for people to ask for cross-product comparisons and they are served poorly right now\n",
    "- Include metadata filtering by review date or add other temporal data since `Time Sensitive` queries are common and are extremely poorly served.\n",
    "- If you run a platform with many sellers (e.g. Amazon), you might allow filtering by seller within a given SKU. This may help address `Counterfeits` which is also a large group that is very poorly served.\n",
    "\n",
    "The exact prioritization would depend on how much effort you thought each potential improvement requires, how effective you expect it to be, etc. But now you have a starting point to inform these decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
