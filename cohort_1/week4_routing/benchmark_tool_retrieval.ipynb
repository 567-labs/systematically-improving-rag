{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Tool Call Choice\n",
    "\n",
    "This week we focused on routers to determine which functions to call or which indices to use for each user-supplied question.\n",
    "\n",
    "This notebook shows how to benchmark function retrieval with synthetic data. It import utils.py which has some more reusable functions.\n",
    "\n",
    "This approach mirrors how we used synthetic questions to measured document retrieval in week 1. \n",
    "\n",
    "## Load Products\n",
    "\n",
    "We test tool-recall with a sample of our product inventory. We load these products below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pydantic/_internal/_config.py:334: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Product(title='Extension Cord', description='A 50-foot extension cord with a heavy-duty jacket for outdoor use. The bright color ensures visibility.'),\n",
       " Product(title='Workbench', description='This portable workbench folds for easy storage and transport. The adjustable clamps hold your workpiece securely in place.'),\n",
       " Product(title='Circular Saw', description='A 7-1/4 inch circular saw with a powerful motor for cutting through wood and metal. The adjustable bevel and depth settings provide versatility.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "import lancedb\n",
    "import random\n",
    "\n",
    "from funcs_to_call import FunctionOption\n",
    "from utils import (\n",
    "    calculate_precision_recall,\n",
    "    FunctionList,\n",
    "    QuestionWithTools,\n",
    "    get_all_tool_call_evals,\n",
    "    describe_tools,\n",
    ")\n",
    "\n",
    "\n",
    "class Product(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "LANCEDB_PATH = \"../week1_bootstrap_evals/lancedb\"\n",
    "\n",
    "try:\n",
    "    db = lancedb.connect(LANCEDB_PATH)\n",
    "    products = db.open_table(\"products\").to_pandas()\n",
    "    products = [\n",
    "        Product(title=row[\"title\"], description=row[\"description\"])\n",
    "        for _, row in products.iterrows()\n",
    "    ]\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"Error loading product data. Run the week1 course notebooks first to create the products DB\"\n",
    "    )\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "random.sample(products, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string listing all available functions to call. We will use this in our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShippingDateRequest: Check when a product will be shipped\n",
      "ShippingCostRequest: Check the cost of shipping a product\n",
      "ProductDimensionsRequest: Check the dimensions of a product\n",
      "PriceHistoryRequest: Check the price history of a product (e.g. identifying historical price fluctuations)\n",
      "ProductComparisonRequest: Compare two products\n",
      "LogDesiredFeatureRequest: Record a user's desire for a certain product feature\n",
      "ExtractDataFromImageRequest: Use our product images with multimodal llm to extract info about the product\n",
      "ProductMaterialsRequest: Check what materials a product is made of\n"
     ]
    }
   ],
   "source": [
    "tool_list = describe_tools(FunctionOption.__args__)\n",
    "print(tool_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 180 synthetic questions. Here is a sample:\n",
      "Question: Can you tell me if these safety glasses have always been this expensive? Also, I need them by next week, will they arrive on time? How much will shipping cost? By the way, are they made of durable materials? And can you compare these with another pair of safety glasses? Lastly, I saw a picture of these glasses, can you get more details from it?\n",
      "    \n",
      "    For context, here is the product description:\n",
      "    Product Description: Safety Glasses: A pair of tinted safety glasses for outdoor use. The UV protection shields your eyes from harmful rays.\n",
      "    \n",
      "func_names=['ProductMaterialsRequest', 'ProductDimensionsRequest']\n",
      "---\n",
      "Question: Will this mini hacksaw fit in small toolboxes?\n",
      "    \n",
      "    For context, here is the product description:\n",
      "    Product Description: Hacksaw: This compact mini hacksaw is perfect for tight spaces. The high-tension blade ensures straight cuts.\n",
      "    \n",
      "func_names=[]\n",
      "---\n",
      "Question: What types of pliers are included in the 7-piece set?\n",
      "    \n",
      "    For context, here is the product description:\n",
      "    Product Description: Pliers Set: A 7-piece pliers set designed for professional use. The set includes a variety of pliers for different tasks, all with non-slip handles.\n",
      "    \n",
      "func_names=[]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "async_client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "def add_context_to_question(question: str, product: Product) -> str:\n",
    "    return f\"\"\"Question: {question}\n",
    "    \n",
    "    For context, here is the product description:\n",
    "    Product Description: {product.title}: {product.description}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def random_tool_selection() -> List[FunctionOption]:\n",
    "    num_tools = random.choice([0, 1, 2])\n",
    "    return random.sample(FunctionOption.__args__, num_tools)\n",
    "\n",
    "\n",
    "async def generate_synthetic_question(product: Product) -> QuestionWithTools:\n",
    "    tools_to_use = random_tool_selection()\n",
    "    prompt = f\"\"\"\n",
    "    Create a realistic question a customer might ask a support chatbot about this product:\n",
    "    {product.title}: {product.description}\n",
    "\n",
    "    The customer knows this is a programmatic chatbot. So they will be terse and lazy (possibly skipping whole/fully formed sentences).\n",
    "    \"\"\"\n",
    "    if tools_to_use:\n",
    "        prompt += f\"\"\"The question should require using these function calls: {tool_list}\n",
    "    \n",
    "    Do not explicitly ask for the function. Instead, ask a question that happens to answerable by calling the function.\n",
    "\n",
    "    For example:\n",
    "    Instead of asking `how long shipping will take`, say `I need it by Friday. Can you make it?`\n",
    "    Instead of asking for product dimensions, ask `Would this fit in a 3x7x4 case?`\n",
    "    Instead of asking for the price history, ask `Is now a good time to buy?`\n",
    "\n",
    "    Real questions tend to be implicit.\n",
    "    Ask questions where it is hard to identify what tool(s) would help an LLM to answer the question.\n",
    "    Assume that we will not make a tool call to look something up if it is already in the product description.\n",
    "\n",
    "    Respond with the question.\n",
    "    \"\"\"\n",
    "    else:\n",
    "        prompt += f\"\"\"Respond with a question that can be answered from the product description without calling any functions:\n",
    "        {tool_list}\n",
    "        \"\"\"\n",
    "\n",
    "    question = await async_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are creating synthetic questions for benchmarking tool retrieval in a retail chatbot.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_model=str,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    tools_names = FunctionList(func_names=[tool.__name__ for tool in tools_to_use])\n",
    "    question_with_context = add_context_to_question(question, product)\n",
    "    return QuestionWithTools(question=question_with_context, required_tools=tools_names)\n",
    "\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    products: List[Product], questions_per_product: int\n",
    ") -> List[QuestionWithTools]:\n",
    "    tasks = [\n",
    "        generate_synthetic_question(product)\n",
    "        for product in products\n",
    "        for _ in range(questions_per_product)\n",
    "    ]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "synthetic_questions = await create_synthetic_dataset(products, questions_per_product=2)\n",
    "\n",
    "print(f\"Generated {len(synthetic_questions)} synthetic questions. Here is a sample:\")\n",
    "for q in random.sample(synthetic_questions, 3):\n",
    "    print(q.question)\n",
    "    print(q.required_tools)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Whether We Call The Correct Functions\n",
    "\n",
    "We'll have a function that's used to retrieve tools (so you can use it broadly), and then another function for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.17\n",
      "Recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "desired_function_calls, actual_function_calls = await get_all_tool_call_evals(\n",
    "    synthetic_questions, tool_list\n",
    ")\n",
    "precision, recall = calculate_precision_recall(\n",
    "    desired_function_calls, actual_function_calls\n",
    ")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
