{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook shows how to make synthetic data to bootstrap evaluation of your retrieval system. This synthetic data will contain many triplets of `(RAG system input, system output, desired chunk to retrieve)`. For the sake of example, the system input will be a question and the output will be an answer. A single triplet of generated data might be:\n",
    "\n",
    "```\n",
    "Q: When should we use retrieval augmented generation? \n",
    "A: We use retrieval augmented generation when we want an LLM to answer a question while considering information it does not already \"know.\" This information could be non-pubic or it might be created after the model's training data cutoff.\n",
    "Chunk ID: 3\n",
    "```\n",
    "\n",
    "Once you have many of these triplets, you can experiments with different retrieval strategies (e.g. different embedding models, embedding vs keyword search, etc) to determine which strategies most consistently retrieve the desired chunks.\n",
    "\n",
    "# A Starting Point\n",
    "\n",
    "A simple approach would follow pseudo code:\n",
    "\n",
    "```\n",
    "synth_data = []\n",
    "for chunk in corpus:\n",
    "    response = call_llm(f\"Give me a JSON array of 10 question/answer pairs derived from this text: {chunk}\")\n",
    "    q_a = json.loads(response.content)\n",
    "    q_a_c = [{'question': q, 'answer': a, 'chunk': chunk} for (q, a) in q_a_pairs]\n",
    "    synth_data.extend(q_a_c)\n",
    "```\n",
    "\n",
    "A practical implementation would address three issues that would arise in the naive pseudo code.\n",
    "\n",
    "| Issue | Solution |\n",
    "|---------|----------|\n",
    "| Inconsistent formatting of LLM response (e.g. different keys) | Instructor library |\n",
    "| Bad questions | Guidance/examples in prompt |\n",
    "| Time waiting for LLM responses when iterating over many chunks | Async LLM calls|\n",
    "\n",
    "# Reusable Code to Bootstrap Evals\n",
    "\n",
    "The code in this notebook addresses these issues. The code is also available as [this script](https://gist.github.com/jxnl/5627c9d463ffe0b085896f7890fab1bf).\n",
    "\n",
    "## Data\n",
    "\n",
    "The following data is here as an example. You will replace it with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class TextChunk(BaseModel):\n",
    "    id: str\n",
    "    content: str\n",
    "\n",
    "sample_chunks = [\n",
    "        TextChunk(\n",
    "            id=\"chunk1\",\n",
    "            content=\"Machine learning is a method of data analysis that automates analytical model building.\",\n",
    "        ),\n",
    "        TextChunk(\n",
    "            id=\"chunk2\",\n",
    "            content=\"Python is a high-level, interpreted programming language known for its simplicity and readability.\",\n",
    "        ),\n",
    "        TextChunk(\n",
    "            id=\"chunk3\",\n",
    "            content=\"Climate change refers to long-term shifts in temperatures and weather patterns, mainly caused by human activities.\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "n_questions = 3 # number of questions to get in each LLM call\n",
    "example_questions = [\n",
    "    \"What is the main topic of this text?\",\n",
    "    \"Can you summarize the key points in this content?\",\n",
    "    \"How does this information relate to current trends in the field?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see how we build questions on a single chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='What is machine learning?', answer='Machine learning is a method of data analysis that automates analytical model building.', chunk_id='chunk1'),\n",
       " ChunkEval(question='What does machine learning automate?', answer='Machine learning automates analytical model building.', chunk_id='chunk1'),\n",
       " ChunkEval(question='What is machine learning used for?', answer='Machine learning is used for data analysis.', chunk_id='chunk1')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Patch the AsyncOpenAI client\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "class ChunkEval(QuestionAnswer):\n",
    "    chunk_id: str\n",
    "\n",
    "async def generate_evals(\n",
    "    chunk: TextChunk, n_questions: int, example_questions: List[str]\n",
    ") -> List[ChunkEval]:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate `{n_questions}` question-answer pairs based on the following content:\n",
    "\n",
    "        <content>\n",
    "        {chunk.content}\n",
    "        </content>\n",
    "\n",
    "        Example questions:\n",
    "        {chr(10).join(f'- {q}' for q in example_questions)}\n",
    "\n",
    "        Generate diverse questions that probe different aspects of the content. \n",
    "        Provide a concise answer for each question.\n",
    "        Do not use the exact example questions, but use them as inspiration for the types of questions to generate.\n",
    "        Do not include answers that are not in the content.\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        pairs = client.chat.completions.create_iterable(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=QuestionAnswer,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return [\n",
    "            ChunkEval(question=pair.question, answer=pair.answer, chunk_id=chunk.id)\n",
    "            async for pair in pairs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "first_chunk_res = await generate_evals(sample_chunks[0], n_questions, example_questions)\n",
    "first_chunk_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `generate_evals` for many chunks in parallel, wrap it with a function that also takes a semaphore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='What is machine learning?', answer='Machine learning is a method of data analysis that automates analytical model building.', chunk_id='chunk1'),\n",
       " ChunkEval(question='What does machine learning automate?', answer='Machine learning automates the building of analytical models.', chunk_id='chunk1'),\n",
       " ChunkEval(question='What field does machine learning belong to?', answer='Machine learning belongs to the field of data analysis.', chunk_id='chunk1')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "class ChunkProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "async def process_chunk(\n",
    "    chunk: TextChunk,\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    semaphore: asyncio.Semaphore\n",
    ") -> List[ChunkEval]:\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            return await generate_evals(chunk, n_questions, example_questions)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing chunk {chunk.id}: {str(e)}\")\n",
    "            raise ChunkProcessingError(f\"Failed to process chunk {chunk.id}\") from e\n",
    "\n",
    "# Test that we get the same results as directly calling generate_evals\n",
    "await process_chunk(sample_chunks[0], n_questions, example_questions, asyncio.Semaphore(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call `process_chunks` with all chunks to build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 9 ChunkEvals.\n",
      "Dataset saved as 'synthetic_eval_dataset.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    chunks: List[TextChunk],\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    max_concurrency: int = 10,\n",
    ") -> List[ChunkEval]:\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [\n",
    "        process_chunk(chunk, n_questions, example_questions, semaphore)\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = []\n",
    "    for result in results:\n",
    "        if isinstance(result, ChunkProcessingError):\n",
    "            print(result)\n",
    "        elif isinstance(result, list):\n",
    "            dataset.extend(result)\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(result)}\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_dataset(dataset: List[ChunkEval], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump([chunk_eval.model_dump() for chunk_eval in dataset], f, indent=2)\n",
    "\n",
    "synthetic_dataset = await create_synthetic_dataset(sample_chunks, n_questions, example_questions)\n",
    "save_dataset(synthetic_dataset, \"synthetic_eval_dataset.json\")\n",
    "\n",
    "print(f\"Generated {len(synthetic_dataset)} ChunkEvals.\")\n",
    "print(\"Dataset saved as 'synthetic_eval_dataset.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is machine learning?</td>\n",
       "      <td>Machine learning is a method of data analysis ...</td>\n",
       "      <td>chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does machine learning automate?</td>\n",
       "      <td>Machine learning automates analytical model bu...</td>\n",
       "      <td>chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can the method of data analysis mentioned...</td>\n",
       "      <td>It can be used for automating analytical model...</td>\n",
       "      <td>chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What type of programming language is Python?</td>\n",
       "      <td>Python is a high-level, interpreted programmin...</td>\n",
       "      <td>chunk2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are two notable features of Python mentio...</td>\n",
       "      <td>Python is known for its simplicity and readabi...</td>\n",
       "      <td>chunk2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How is Python executed?</td>\n",
       "      <td>Python is an interpreted programming language.</td>\n",
       "      <td>chunk2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is climate change?</td>\n",
       "      <td>Climate change refers to long-term shifts in t...</td>\n",
       "      <td>chunk3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is mainly causing climate change accordin...</td>\n",
       "      <td>Human activities are mainly causing climate ch...</td>\n",
       "      <td>chunk3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What does the term 'long-term shifts' refer to...</td>\n",
       "      <td>It refers to changes in temperatures and weath...</td>\n",
       "      <td>chunk3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                          What is machine learning?   \n",
       "1               What does machine learning automate?   \n",
       "2  What can the method of data analysis mentioned...   \n",
       "3       What type of programming language is Python?   \n",
       "4  What are two notable features of Python mentio...   \n",
       "5                            How is Python executed?   \n",
       "6                            What is climate change?   \n",
       "7  What is mainly causing climate change accordin...   \n",
       "8  What does the term 'long-term shifts' refer to...   \n",
       "\n",
       "                                              answer chunk_id  \n",
       "0  Machine learning is a method of data analysis ...   chunk1  \n",
       "1  Machine learning automates analytical model bu...   chunk1  \n",
       "2  It can be used for automating analytical model...   chunk1  \n",
       "3  Python is a high-level, interpreted programmin...   chunk2  \n",
       "4  Python is known for its simplicity and readabi...   chunk2  \n",
       "5     Python is an interpreted programming language.   chunk2  \n",
       "6  Climate change refers to long-term shifts in t...   chunk3  \n",
       "7  Human activities are mainly causing climate ch...   chunk3  \n",
       "8  It refers to changes in temperatures and weath...   chunk3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [(i.question, i.answer, i.chunk_id) for i in synthetic_dataset]\n",
    "pd.DataFrame(data, columns=[\"question\", \"answer\", \"chunk_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
