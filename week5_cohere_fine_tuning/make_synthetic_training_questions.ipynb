{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "We will test whether fine-tuning our reranker improves the [recall metrics from week 1](https://github.com/567-labs/systematically-improving-rag/tree/main/week1_bootstrap_evals)\n",
    "\n",
    "We will fine-tune the reranker on ~1000 `(question, review)` pairs. The question will be the request/input to the model and the review is the response/output. Our goal is for the better reranker to improve our recall metrics. \n",
    "\n",
    "To avoid leakage, we must use separate data for fine-tuning vs evaluating retrieval quality. This notebook generates the fine-tuning data. In practice, you will use your real data rather than generating synthetic data for fine-tuning.\n",
    "\n",
    "To add some small differences between our fine-tuning data and our recall eval data (increasing realism), we use Sonnet 3.5 to generate this data (whereas we used gpt-4o for the recall eval data)\n",
    "\n",
    "## Load Products and Create Some Reviews\n",
    "\n",
    "We will load the products database created in week 1. If you haven't run the week 1 code, do that so we can load the products database.\n",
    "\n",
    "This cell will then create reviews of these products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lancedb\n",
    "import pandas as pd\n",
    "import instructor\n",
    "from anthropic import AsyncAnthropic\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)\n",
    "\n",
    "\n",
    "class Product(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    review: str\n",
    "\n",
    "\n",
    "class AllObjectInfo(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "async_client = instructor.from_anthropic(AsyncAnthropic())\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"../week1_bootstrap_evals/lancedb\")\n",
    "products = db.open_table(\"products\").to_pandas()\n",
    "\n",
    "\n",
    "async def make_reviews(\n",
    "    product: Product, n: int, semaphore: asyncio.Semaphore = asyncio.Semaphore(1)\n",
    ") -> List[AllObjectInfo]:\n",
    "    async with semaphore:\n",
    "        prompt = f\"\"\"\n",
    "        Write {n} realistic but detailed/specific product reviews that might show up on a hardware store's website.\n",
    "\n",
    "        The reviews should be about the following product:\n",
    "        Product Title: {product.title}\n",
    "        Product Description: {product.description}\n",
    "        \n",
    "        Add many relevant and concrete facts about the products (this is for synthetic data generation, make up facts about each product as necessary).\n",
    "\n",
    "        To see the format of a possible review, here is a review for a saw:\n",
    "        ```\n",
    "        I've enjoyed using this saw. It is lightweight and the battery lasts longer than other brands.\n",
    "        I've been using it for 3 years now and it has been very durable. It was twice as expensive as the PX-500. But\n",
    "        it is comfortable to hold because of the light weight.\n",
    "        ```\n",
    "\n",
    "        Respond only with the reviews, and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            result = await async_client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20240620\",\n",
    "                response_model=List[Review],\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0,\n",
    "                max_tokens=1000,\n",
    "            )\n",
    "            return [\n",
    "                AllObjectInfo(\n",
    "                    title=product.title,\n",
    "                    description=product.description,\n",
    "                    review=r.review,\n",
    "                )\n",
    "                for r in result\n",
    "            ]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "async def make_reviews_batch(\n",
    "    max_concurrency: int = 10, reviews_per_product: int = 4\n",
    ") -> List[AllObjectInfo]:\n",
    "    out = []\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [\n",
    "        make_reviews(Product(**o), reviews_per_product, semaphore)\n",
    "        for _, o in products.iterrows()\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    for r in results:\n",
    "        if isinstance(r, Exception):\n",
    "            print(f\"Error encountered: {r}\")  # Print out any exceptions\n",
    "        else:\n",
    "            out.extend(r)\n",
    "    return out\n",
    "\n",
    "\n",
    "reviews = await make_reviews_batch(reviews_per_product=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Make question <-> review pairs where we know what reviews are associated with each question. We do this by giving the review to the LLM and asking for a question that is answered by that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question(BaseModel):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class TrainingPair(BaseModel):\n",
    "    question: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "async def generate_ft_pairs(\n",
    "    obj_info: AllObjectInfo, n_questions: int, semaphore: asyncio.Semaphore\n",
    ") -> List[TrainingPair]:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate `{n_questions}` question-answer pairs about a {obj_info.title}. The answers should primarily be derived from information in this product review:\n",
    "\n",
    "        <content>\n",
    "        {obj_info.review}\n",
    "        </content>\n",
    "\n",
    "        While they should contain information from the product review, you may also find it helpful context to see a product description:\n",
    "        <content>\n",
    "        {obj_info.description}\n",
    "        </content>\n",
    "\n",
    "        Example questions to consider when forming your question:\n",
    "        - \"What are the products strengths?\",\n",
    "        - \"What are the products weaknesses?\",\n",
    "        - \"What features or quirks stood out?\",\n",
    "\n",
    "        Provide a concise and specific answer for each question.\n",
    "        Do not use the exact example questions. Use them only as inspiration for the types of more specific questions to generate.\n",
    "        Do not include answers that are not in the content.\n",
    "        Questions should ask about product characteristics (e.g. durability) and answers should refer to product characteristics without referring to the reviewer specifically.\n",
    "        Stylistically, the questions should resemble what people would ask a RAG-based answer bot on a retailer's website. So they can be a little informal, messy or scattered.\n",
    "        \"\"\"\n",
    "\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            questions = await async_client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20240620\",\n",
    "                response_model=List[Question],\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0,\n",
    "                max_tokens=600,\n",
    "            )\n",
    "            return [\n",
    "                TrainingPair(question=q.question, review=obj_info.review)\n",
    "                for q in questions\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating evals: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "async def make_all_ft_data(\n",
    "    reviews: List[AllObjectInfo],\n",
    "    n_questions: int,\n",
    "    max_concurrency: int = 10,\n",
    ") -> List[TrainingPair]:\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [generate_ft_pairs(review, n_questions, semaphore) for review in reviews]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = [item for r in results if isinstance(r, list) for item in r]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "ft_dataset = await make_all_ft_data(reviews, n_questions=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1029 Training Pairs.\n",
      "Dataset saved as 'ft_dataset.jsonl'\n"
     ]
    }
   ],
   "source": [
    "def save_dataset(dataset: List[TrainingPair], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in dataset:\n",
    "            to_write = {\n",
    "                \"query\": item.question,\n",
    "                \"relevant_passages\": [item.review],\n",
    "            }\n",
    "            f.write(json.dumps(to_write) + \"\\n\")\n",
    "\n",
    "\n",
    "save_dataset(ft_dataset, \"ft_dataset.jsonl\")\n",
    "\n",
    "print(f\"Generated {len(ft_dataset)} Training Pairs.\")\n",
    "print(\"Dataset saved as 'ft_dataset.jsonl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
