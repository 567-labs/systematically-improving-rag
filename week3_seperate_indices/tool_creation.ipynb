{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "We started our course with:\n",
    "- [Week 1: Bootstrap retrieval evaluation](https://github.com/567-labs/systematically-improving-rag/tree/main/week1_bootstrap_evals)\n",
    "- [Week 2: Classify queries to prioritize improvements](https://github.com/567-labs/systematically-improving-rag/tree/main/week2_question_classification)\n",
    "\n",
    "The improvements you'll prioritize based on week 2 include:\n",
    "- Adding data sources\n",
    "- Adding new indices to improve retrieval on existing sources\n",
    "- Extract more information from existing data\n",
    "    - Pre-processing so results are ready at query time\n",
    "    - Post-processing so results are calculated at query time\n",
    "\n",
    "This notebook shows sample code for handling new data types (e.g. images, tables and 3rd party APIs), adding indices, and extracting more information from existing data sources.\n",
    "\n",
    "We'll add routers in week 4 to ensure we're calling the correct tools after we build them.\n",
    "\n",
    "# Example\n",
    "\n",
    "We continue our example of a hardware e-commerce site answering user questions with a RAG system that retrieves previous product reviews.\n",
    "\n",
    "Many questions won't be answered by product reviews, but we could look them up from other sources. For example:\n",
    "- `How many of these are available to be shipped right now?`\n",
    "- `How much will it cost to ship this item to Florida?`\n",
    "\n",
    "We can answer questions like this with tool calls on new data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pydantic/_internal/_config.py:334: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 1, 2024.\n",
      "$15.99.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "\n",
    "from typing import Annotated, Any, Iterable, List, Literal, Optional\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ShippingDateRequest(BaseModel):\n",
    "    sku: str\n",
    "\n",
    "\n",
    "class ShippingCostRequest(BaseModel):\n",
    "    sku: str\n",
    "    shipping_location: str\n",
    "\n",
    "\n",
    "def get_available_shipping_date(sku: str) -> str:\n",
    "    \"\"\"A mock function\"\"\"\n",
    "    return \"September 1, 2024.\"\n",
    "\n",
    "\n",
    "def get_shipping_cost(sku: str, shipping_location: str) -> str:\n",
    "    \"\"\"A mock function\"\"\"\n",
    "    return \"$15.99.\"\n",
    "\n",
    "\n",
    "basic_client = instructor.from_openai(openai.OpenAI())\n",
    "tools_client = instructor.from_openai(\n",
    "    openai.OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS\n",
    ")\n",
    "\n",
    "\n",
    "example_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You must always use tools\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"A user asked the following question about a product with sku 1234567890.\n",
    "When will this product be in stock again? And how much will it cost to ship this item to Florida?\n",
    "            \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "function_calls = tools_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=example_messages,\n",
    "    response_model=Iterable[ShippingDateRequest | ShippingCostRequest],\n",
    ")\n",
    "\n",
    "for call in function_calls:\n",
    "    if isinstance(call, ShippingDateRequest):\n",
    "        result = get_available_shipping_date(call.sku)\n",
    "    elif isinstance(call, ShippingCostRequest):\n",
    "        result = get_shipping_cost(call.sku, call.shipping_location)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling arbitrary functions as we've seen hear opens up a wide range of data sources.\n",
    "\n",
    "- Read from a database\n",
    "- Calculations\n",
    "- Side effects (e.g. write to a database, send an email)\n",
    "- More LLM calls\n",
    "\n",
    "But you can also call functions that do more than reading data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging User Requests\n",
    "\n",
    "We decide to store facts about customers and their interest in a database, so we can make better recommendations in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging data for dan@gmail.com. Fact: looking for an axe with a rubberized handle.\n",
      "Logging data for dan@gmail.com. Fact: has nerve damage in elbow.\n",
      "Logging data for dan@gmail.com. Fact: finds hard handles painful.\n"
     ]
    }
   ],
   "source": [
    "class Fact(BaseModel):\n",
    "    person: str\n",
    "    fact: str\n",
    "\n",
    "\n",
    "def log_requests(person, fact) -> None:\n",
    "    \"\"\"A mock function\"\"\"\n",
    "    print(f\"Logging data for {person}. Fact: {fact}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "# Could improve this with examples in the prompt\n",
    "function_calls = tools_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Extract a list of atomic facts about a person that may help us recommend better tools for them in the future.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"dan@gmail.com made the following request while viewing a 7\" axe:\n",
    "            I'm looking for an axe with a rubberized handle. I have nerve damage in my elbow which makes hard handles painful. How hard is this axe handle? I will buy an axe with a soft handle if I can find it.\"\n",
    "            \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    response_model=Iterable[Fact],\n",
    "    tools=[{\"type\": \"function\", \"function\": log_requests}],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "for call in function_calls:\n",
    "    log_requests(call.person, call.fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Structured Data\n",
    "\n",
    "These plain language facts are useful for some workflows (I could iterate over them and figure out which users are especially interested in some new product).\n",
    "\n",
    "But many RAG capabilities benefit from structured data (especially for improving retrieval quality). This is very natural with Instructor.\n",
    "\n",
    "How would you ensure your system can answer questions like \"What is a German-made axe that is at least 20 cm long with a wooden handle?\"\n",
    "\n",
    "We'll need to extract structured data from the request (and possibly from product descriptions). For the sake of example, we'll preprocess axe descriptions to populate a database of product specs which we can later query (details of querying will be in week 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_type: axe\n",
      "handle_material: spruce\n",
      "blade_material: carbon steel\n",
      "weight_grams: None\n",
      "color: None\n",
      "length_cm: 30\n",
      "country_of_origin: Canada\n"
     ]
    }
   ],
   "source": [
    "class HandToolStats(BaseModel):\n",
    "    tool_type: Optional[Literal[\"axe\", \"hammer\", \"screwdriver\", \"saw\", \"other\"]]\n",
    "    handle_material: Optional[str] = None\n",
    "    blade_material: Optional[str] = None\n",
    "    weight_grams: Optional[int] = None\n",
    "    color: Optional[str] = None\n",
    "    length_cm: Optional[int] = None\n",
    "    country_of_origin: Optional[str] = None\n",
    "\n",
    "\n",
    "# Could improve this with examples in the prompt\n",
    "axe_specs = basic_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract specs from the product description.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "            This Canadian axe is made with the finest spruce and carbon steel. It is 12 inches long\n",
    "            \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    response_model=HandToolStats,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "for s in axe_specs:\n",
    "    print(f\"{s[0]}: {s[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have some `None` values in the extracted data, and people won't always query over all data. You probably already see how you could put these together to answer questions in real-time using SQL queries.\n",
    "\n",
    "# Images\n",
    "\n",
    "We've looked at text input so far. But it's straightforward to extend this to images.\n",
    "\n",
    "Let's extract some stats from an axe image instead of a written description\n",
    "\n",
    "![Carpenter's axe](https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Carpenter%27s_axe.jpg/340px-Carpenter%27s_axe.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HandToolStats(tool_type='axe', handle_material='wood', blade_material='metal', weight_grams=None, color=None, length_cm=None, country_of_origin=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_to_tool_stats(url: str) -> HandToolStats:\n",
    "    return basic_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_model=HandToolStats,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Extract specs from the product description. \n",
    "             Include all fields you can extract from the image.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": url},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "\n",
    "img_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Carpenter%27s_axe.jpg/340px-Carpenter%27s_axe.jpg\"\n",
    "specs = image_to_tool_stats(img_url)\n",
    "specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's nothing special about extraction and images as a pair.\n",
    "\n",
    "We could have asked \"What's in this image\" and gotten a string description.\n",
    "\n",
    "Or if the image can be interpreted as a table, we can ask for that table\n",
    "\n",
    "### Are A Prompt and A Response Model All You Need?\n",
    "\n",
    "To see this in a stripped down form, we'll do data extraction from an image in a familiar format. Then we'll add some structure and extract pandas DataFrames from images.\n",
    "\n",
    "A user may ask what will be trendy for hardware materials in the coming years. \n",
    "\n",
    "If we have reports with images like this, we have a source to answer their question\n",
    "\n",
    "<img src=https://market.us/wp-content/uploads/2023/02/Cabinet-Hardware-Market-Size.png height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table(BaseModel):\n",
    "    caption: str\n",
    "    md_dataframe: str\n",
    "\n",
    "\n",
    "def img_to_md_table(url: str) -> List[Table]:\n",
    "    return basic_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens=4000,\n",
    "        response_model=List[Table],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": url},\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"\n",
    "                            Analyze the image to determine appropriate headers for output tables.\n",
    "                            For each identified table, create an informative h2 title and a concise description of the contents.\n",
    "                            Finally, output the markdown representation of all data in the table/graph.\n",
    "\n",
    "                            Escape the markdown table properly, and make sure to include the caption and the dataframe.\n",
    "                            Only return a markdown table in dataframe, nothing else. Make sure to capture all data that should be in the table.\n",
    "\n",
    "                            Capture visual data that is not explicitly labeled with text from the image\n",
    "                        \"\"\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Global Cabinet Hardware Market Size, by Material, 2022-2032 (USD Billion) \n",
      " | Year | Metal | Plastic | Ceramic | Glass | Wood |\n",
      "|------|-------|---------|---------|-------|------|\n",
      "| 2022 | 3.5   | 2.5     | 1.5     | 1.0   | 1.18 |\n",
      "| 2023 | 3.7   | 2.7     | 1.6     | 1.1   | 1.27 |\n",
      "| 2024 | 3.9   | 2.9     | 1.7     | 1.2   | 1.31 |\n",
      "| 2025 | 4.1   | 3.1     | 1.8     | 1.3   | 1.39 |\n",
      "| 2026 | 4.3   | 3.3     | 1.9     | 1.4   | 1.46 |\n",
      "| 2027 | 4.5   | 3.5     | 2.0     | 1.5   | 1.56 |\n",
      "| 2028 | 4.7   | 3.7     | 2.1     | 1.6   | 1.66 |\n",
      "| 2029 | 4.9   | 3.9     | 2.2     | 1.7   | 1.68 |\n",
      "| 2030 | 5.1   | 4.1     | 2.3     | 1.8   | 1.78 |\n",
      "| 2031 | 5.3   | 4.3     | 2.4     | 1.9   | 1.89 |\n",
      "| 2032 | 5.5   | 4.5     | 2.5     | 2.0   | 2.39 |\n"
     ]
    }
   ],
   "source": [
    "url = \"https://market.us/wp-content/uploads/2023/02/Cabinet-Hardware-Market-Size.png\"\n",
    "\n",
    "for table in img_to_md_table(url):\n",
    "    print(\"-----------------------------------\")\n",
    "    print(table.caption, \"\\n\", table.md_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extract info to tables for things that are less obviously \"tables\" in their raw form.\n",
    "\n",
    "<img src=\"https://www.transparencymarketresearch.com/images/household-and-diy-hand-tools-market.jpg\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Market Drivers \n",
      " | Market Drivers |\n",
      "|----------------|\n",
      "| Rise in e-commerce |\n",
      "| Surge in trend of do-it-yourself activities |\n",
      "-----------------------------------\n",
      "Market Revenue \n",
      " | Year | Revenue (US$ Bn) | CAGR (2023-2031) |\n",
      "|------|------------------|------------------|\n",
      "| 2022 | 17.9             | 4.5%             |\n",
      "-----------------------------------\n",
      "Sales Channels \n",
      " | Sales Channels |\n",
      "|----------------|\n",
      "| Online Sales   |\n",
      "| Retail Sales   |\n",
      "| Distributor Sales |\n",
      "-----------------------------------\n",
      "Key Players \n",
      " | Key Players                       |\n",
      "|----------------------------------|\n",
      "| Akar Tools Ltd.                  |\n",
      "| Apex Tools Group LLC             |\n",
      "| Channellock, Inc.                |\n",
      "| JK Files and Engineering Limited |\n",
      "| Kennametal Inc.                  |\n",
      "| Klein Tools, Inc.                |\n",
      "| Snap-on Incorporated             |\n",
      "| Stanley Black & Decker, Inc.     |\n",
      "| Wera Tools                       |\n",
      "-----------------------------------\n",
      "Product Types \n",
      " | Product Types              |\n",
      "|----------------------------|\n",
      "| General Purpose Tools      |\n",
      "| Metal Cutting Tools        |\n",
      "| Layout and Measuring Tools |\n",
      "| Taps and Dies              |\n",
      "-----------------------------------\n",
      "Regional Market Share \n",
      " | Region      | Market Share (2022) |\n",
      "|-------------|---------------------|\n",
      "| Asia Pacific| Largest             |\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.transparencymarketresearch.com/images/household-and-diy-hand-tools-market.jpg\"\n",
    "\n",
    "for table in img_to_md_table(url):\n",
    "    print(\"-----------------------------------\")\n",
    "    print(table.caption, \"\\n\", table.md_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to DataFrame\n",
    "\n",
    "Much more is possible with DataFrames than Markdown. So we likely want to extract a DataFrame. This requires some extra code (primarily for conversion to/from the DataFrame). We can see it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Global Cabinet Hardware Market Size by Material, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2032</span> <span style=\"font-weight: bold\">(</span>USD Billion<span style=\"font-weight: bold\">)</span> \n",
       "         Metal   Plastic   Ceramic   Glass   Wood \n",
       " Year                                            \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.87</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.90</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.45</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.49</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.15</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.11</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.55</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.04</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.52</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.30</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.65</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.10</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.56</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.79</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.59</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.80</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.20</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.61</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.18</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.88</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.94</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.29</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.67</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2027</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.51</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.13</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.06</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.37</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.70</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2028</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.75</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.31</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.15</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.43</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.72</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2029</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.15</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.61</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.30</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.53</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.79</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2030</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.55</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.45</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.63</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.84</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2031</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.21</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.60</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.73</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.90</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2032</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.35</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.51</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.75</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.84</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Global Cabinet Hardware Market Size by Material, \u001b[1;36m2022\u001b[0m-\u001b[1;36m2032\u001b[0m \u001b[1m(\u001b[0mUSD Billion\u001b[1m)\u001b[0m \n",
       "         Metal   Plastic   Ceramic   Glass   Wood \n",
       " Year                                            \n",
       " \u001b[1;36m2022\u001b[0m     \u001b[1;36m3.87\u001b[0m      \u001b[1;36m2.90\u001b[0m      \u001b[1;36m1.45\u001b[0m    \u001b[1;36m0.97\u001b[0m   \u001b[1;36m0.49\u001b[0m\n",
       " \u001b[1;36m2023\u001b[0m     \u001b[1;36m4.15\u001b[0m      \u001b[1;36m3.11\u001b[0m      \u001b[1;36m1.55\u001b[0m    \u001b[1;36m1.04\u001b[0m   \u001b[1;36m0.52\u001b[0m\n",
       " \u001b[1;36m2024\u001b[0m     \u001b[1;36m4.40\u001b[0m      \u001b[1;36m3.30\u001b[0m      \u001b[1;36m1.65\u001b[0m    \u001b[1;36m1.10\u001b[0m   \u001b[1;36m0.56\u001b[0m\n",
       " \u001b[1;36m2025\u001b[0m     \u001b[1;36m4.79\u001b[0m      \u001b[1;36m3.59\u001b[0m      \u001b[1;36m1.80\u001b[0m    \u001b[1;36m1.20\u001b[0m   \u001b[1;36m0.61\u001b[0m\n",
       " \u001b[1;36m2026\u001b[0m     \u001b[1;36m5.18\u001b[0m      \u001b[1;36m3.88\u001b[0m      \u001b[1;36m1.94\u001b[0m    \u001b[1;36m1.29\u001b[0m   \u001b[1;36m0.67\u001b[0m\n",
       " \u001b[1;36m2027\u001b[0m     \u001b[1;36m5.51\u001b[0m      \u001b[1;36m4.13\u001b[0m      \u001b[1;36m2.06\u001b[0m    \u001b[1;36m1.37\u001b[0m   \u001b[1;36m0.70\u001b[0m\n",
       " \u001b[1;36m2028\u001b[0m     \u001b[1;36m5.75\u001b[0m      \u001b[1;36m4.31\u001b[0m      \u001b[1;36m2.15\u001b[0m    \u001b[1;36m1.43\u001b[0m   \u001b[1;36m0.72\u001b[0m\n",
       " \u001b[1;36m2029\u001b[0m     \u001b[1;36m6.15\u001b[0m      \u001b[1;36m4.61\u001b[0m      \u001b[1;36m2.30\u001b[0m    \u001b[1;36m1.53\u001b[0m   \u001b[1;36m0.79\u001b[0m\n",
       " \u001b[1;36m2030\u001b[0m     \u001b[1;36m6.55\u001b[0m      \u001b[1;36m4.91\u001b[0m      \u001b[1;36m2.45\u001b[0m    \u001b[1;36m1.63\u001b[0m   \u001b[1;36m0.84\u001b[0m\n",
       " \u001b[1;36m2031\u001b[0m     \u001b[1;36m6.95\u001b[0m      \u001b[1;36m5.21\u001b[0m      \u001b[1;36m2.60\u001b[0m    \u001b[1;36m1.73\u001b[0m   \u001b[1;36m0.90\u001b[0m\n",
       " \u001b[1;36m2032\u001b[0m     \u001b[1;36m7.35\u001b[0m      \u001b[1;36m5.51\u001b[0m      \u001b[1;36m2.75\u001b[0m    \u001b[1;36m1.84\u001b[0m   \u001b[1;36m0.95\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from io import StringIO\n",
    "from typing import Annotated, Any, List\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    BeforeValidator,\n",
    "    PlainSerializer,\n",
    "    InstanceOf,\n",
    "    WithJsonSchema,\n",
    ")\n",
    "import instructor\n",
    "import pandas as pd\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "client = instructor.from_openai(\n",
    "    client=OpenAI(),\n",
    "    mode=instructor.Mode.TOOLS,\n",
    ")\n",
    "\n",
    "\n",
    "def md_to_df(data: Any) -> Any:\n",
    "    if isinstance(data, str):\n",
    "        return (\n",
    "            pd.read_csv(\n",
    "                StringIO(data),  # Get rid of whitespaces\n",
    "                sep=\"|\",\n",
    "                index_col=1,\n",
    "            )\n",
    "            .dropna(axis=1, how=\"all\")\n",
    "            .iloc[1:]\n",
    "            .map(lambda x: x.strip())\n",
    "        )  # type: ignore\n",
    "    return data\n",
    "\n",
    "\n",
    "MarkdownDataFrame = Annotated[\n",
    "    InstanceOf[pd.DataFrame],\n",
    "    BeforeValidator(md_to_df),\n",
    "    PlainSerializer(lambda x: x.to_markdown()),\n",
    "    WithJsonSchema(\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"\"\"\n",
    "                The markdown representation of the table, \n",
    "                each one should be tidy, do not try to join tables\n",
    "                that should be seperate\"\"\",\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    caption: str\n",
    "    dataframe: MarkdownDataFrame\n",
    "\n",
    "\n",
    "class MultipleTables(BaseModel):\n",
    "    tables: List[Table]\n",
    "\n",
    "\n",
    "def extract(url: str) -> MultipleTables:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens=4000,\n",
    "        response_model=MultipleTables,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": url},\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"\n",
    "                            Analyze the image to determine appropriate headers for output tables.\n",
    "                            For each identified table, create an informative h2 title and a concise description of the contents.\n",
    "                            Finally, output the markdown representation of all data in the table/graph.\n",
    "\n",
    "                            Escape the markdown table properly, and make sure to include the caption and the dataframe.\n",
    "                            Only return a markdown table in dataframe, nothing else. Make sure to capture all data that should be in the table.\n",
    "\n",
    "                            Capture visual data that is not explicitly labeled with text from the image\n",
    "                        \"\"\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "\n",
    "url = \"https://market.us/wp-content/uploads/2023/02/Cabinet-Hardware-Market-Size.png\"\n",
    "for table in extract(url).tables:\n",
    "    console.print(table.caption, \"\\n\", table.dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've seen that you can (and likely will) create many tools. But it would be slow (and possibly harmful) to call all tools for all queries.\n",
    "\n",
    "The `benchmark_tool_retrieval.ipynb` notebook will show how to measure tool retrieval with synthetic data much like we benchmarked content retrieval with synthetic data in week 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadquery",
   "language": "python",
   "name": "cadquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
